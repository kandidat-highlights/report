\chapter{Introduction}

This thesis will evaluate if it is possible to minimise the irrelevant notifications by using an ANN. In today’s digital age it can be hard keeping track of all the content and conversations on different social platforms; such as Slack, Facebook Messenger, WhatsApp and Reddit. People do not want to miss the conversations or news that might interest them, rather get instant feedback when these conversations or news take place. However, the notifications of today are indiscriminate in that it is hard to get notified when something of interest is posted while not being notified at all times. Some applications have tried to solve this by allowing manual “mentioning” or “highlighting” of a person to get their attention; Slack is one example of this \parencite{slack}. However, these functions put a constraint on the users where they need to figure out by themselves who might be interested in some content. It is also deemed as bad manners to highlight a person - or a group of people - too often. Studies have even shown that an excessive amount of notifications can lead to stress \parencite{relaffinity}.
\\\\
One solution to this problem could be a software that when given new content would automatically highlight/notify specific users that is deemed interested. Such a software would relieve a user of the stress of an abundance of notifications and contribute to an overall better experience for them. Even if it would not be perfect, a less amount of irrelevant notifications could potentially make a big difference.
%Such a middle ground would be beneficial for both the users and the owner of the platform. It would make it easier for users to find interesting content which would improve the overall experience for the average user - this, in turn, benefits the owner of the platform as its users get more satisfied overall.
\\\\
Similar problems to the above mentioned have been solved in other fields like electronic commerce. Amazon uses a technique called recommender systems to recommend new items for their users \parencite{amazonfiltering}. Their recommender system is not based on ANN but rather compares the similarity between new products and products that a user has previously bought or rated \parencite{amazonfiltering}. What motivates the use of ANN over recommender systems in this project is their ability to capture a deeper meaning of text content which we believe could be useful when modelling what people like or dislike. 

\section{Purpose}
The aim of this project is to evaluate the performance of deep recurrent neural networks to personalise recommendations for users on social platforms. By using a neural network trained for this task an application should then be able to use its predictions to individually notify users when content interesting to them is published.

\section{Problem Description}
To complete the purpose of the project, the correlation between some content on the platform and a users' interest needs to be modelled. This will be attempted using an artificial neural network. In order to successfully model this problem there are a number of factors that must be considered.
\\\\
First of all, in order to use an artificial neural network a dataset which can be used for training is needed. When a dataset is obtained, the ANN must be modelled to capture the relation between the contents of a text and a user's interest. The modelling is a key part of the problem where a lot of experimentation with hyperparameters is needed. The number of layers, their sizes and different functions in the network needs to be examined. Once an optimal performance has been achieved it also needs to be compared with some baseline in order to evaluate whether this method is good in practice or not. These problems, as described in more detail below,  must be addressed and solved in order to achieve the goal of the project.

\subsection{Selecting a Dataset}\label{sec:select_dataset}
For all datasets available not all are suited to the task. The dataset needs to satisfy the following constraints: 
\vspace*{0.25cm}
\begin{itemize}
    \item It must be sufficiently large
    \item It must be labelled
\end{itemize}
\vspace*{0.25cm}
As part of this project, potential datasets that fulfilled the above constraints were examined to select the most suitable one.

\subsection{Finding Hyperparameters}
The hyperparameters for the ANN will in the end determine its performance. This is since the hyperparameters determine characteristics of the ANN - its shape, size and behaviour. Some of the hyperparameters that were  examined are described below:
\vspace*{0.25cm}
\begin{itemize}
    \item Depth of network, how many layers the network needs
    \item Bredth of layers, how many nodes each layer has
    \item Size of embedding matrix
    \item Learning rate
\end{itemize}

\subsection{Comparing with a Baseline}
When evaluating the performance of the network one or more baselines are needed as reference points. It is not sufficient to say that the model simply \textit{performs well}, if there is no context \textit{well} could mean just about anything. It is therefore important to have one or more baselines to serve as references. How well the result of the project compares against existing solutions/baselines will determine whether artificial neural networks is a good choice for solving the problem or not. This comparison fulfils the projects purpose of evaluating the performance of ANN for the described problem.
\\\\
If these three objectives have been fulfilled the 

\section{Scope}
This project will evaluate the possibilities of using artificial neural networks to accurately be able to recommend users of a social platform that will be interested in new content posted on the platform.

\subsection{Limitations}
This project will mostly be scientific and will not focus on business applications of the problem.
\\\\
Due  to  technical  limitations  regarding  computing  power  and  available  data  the number of users that will be considered when recommending will be smaller than what would likely be desired in a commercial implementation. This  is  to  make  the training  of  the  network  take  less  time  and  thereby make it possible to perform more experiments. The total number of users that will be considered will be fixed to contain the initial number of users and a buffer for new users. When adding a new user the model remains trained, and only needs to learn from the new user’s data.
\\\\
One issue that arises when dealing with data of this kind is the ethical concern regarding integrity. It is not hard to imagine that a system that could tell whether or not something is of interest to a specific person could be abused. The system could perhaps discover areas of interest that a person would have wished to keep private, this is just one example of potentially many problems. Although this is an important issue the thesis will not cover this subject. 